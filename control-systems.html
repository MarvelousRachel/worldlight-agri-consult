<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Worldlight Agri Consult Labs - Advanced Control System Implementation for underwater and agricultural robotics">
  <meta name="keywords" content="control systems, robotics, IMU, LiDAR, computer vision, agricultural automation, underwater robotics">
  <meta name="author" content="Worldlight Agri Consult Labs">
  <title>Control System Implementation - Worldlight Agri Consult Labs</title>
  <link rel="stylesheet" href="css/style.css">
  <style>
    .technical-section {
      background: linear-gradient(135deg, #f8f9fa, #e9ecef);
      border-left: 4px solid #007BFF;
      padding: 25px;
      margin: 20px 0;
      border-radius: 8px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .code-block {
      background: #2d3748;
      color: #e2e8f0;
      padding: 20px;
      border-radius: 8px;
      font-family: 'Courier New', monospace;
      font-size: 14px;
      line-height: 1.5;
      overflow-x: auto;
      margin: 15px 0;
      border: 1px solid #4a5568;
    }
    .highlight {
      background: linear-gradient(135deg, #4CAF50, #45a049);
      color: white;
      padding: 15px;
      border-radius: 8px;
      margin: 15px 0;
    }
    .spec-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
      margin: 20px 0;
    }
    .spec-card {
      background: white;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      border-left: 4px solid #007BFF;
    }
    .performance-stats {
      background: linear-gradient(135deg, #667eea, #764ba2);
      color: white;
      padding: 20px;
      border-radius: 10px;
      margin: 20px 0;
    }
    .stats-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
      gap: 15px;
      margin-top: 15px;
    }
    .stat-item {
      text-align: center;
      padding: 10px;
      background: rgba(255,255,255,0.1);
      border-radius: 8px;
    }
    .feature-list {
      background: #f8f9fa;
      padding: 20px;
      border-radius: 8px;
      margin: 15px 0;
    }
    .feature-list ul {
      margin: 0;
      padding-left: 20px;
    }
    .feature-list li {
      margin: 8px 0;
      color: #2c3e50;
    }
    h3 {
      color: #007BFF;
      border-bottom: 2px solid #007BFF;
      padding-bottom: 5px;
    }
  </style>
</head>
<body>
  <header>
    <h1>Worldlight Agri Consult Labs</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="agricultural_technology_portfolio.html">Tech Portfolio</a></li>
        <li><a href="our-expertise.html">Our Expertise</a></li>
        <li><a href="control-systems.html" class="active">üî¨ Control Systems</a></li>
        <li><a href="agricultural_technology_portfolio.html">Portfolio</a></li>
        <li><a href="about.html">About Us</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <div class="highlight">
      <h1>üî¨ Control System Implementation</h1>
      <p>Advanced sensor fusion and control algorithms for underwater and agricultural robotics applications, featuring real-time processing and AI-driven optimization.</p>
    </div>

    <div class="technical-section">
      <h2>üéØ System Overview</h2>
      <p>Our control system integrates multi-sensor data acquisition, advanced computer vision, and machine learning for autonomous operation in challenging environments. The system demonstrates robust performance in underwater turbidity conditions (1.5‚Äì7.5 NTU) with real-time processing capabilities.</p>
      
      <div class="spec-grid">
        <div class="spec-card">
          <h4>üîß Hardware Platform</h4>
          <ul>
            <li><strong>IMU:</strong> LPMS-NAV3 (100 Hz)</li>
            <li><strong>LiDAR:</strong> RealSense L515</li>
            <li><strong>UWB:</strong> LinkTrack (6.5 cm accuracy)</li>
            <li><strong>Vision:</strong> RGB-D at 30 Hz</li>
          </ul>
        </div>
        <div class="spec-card">
          <h4>üíª Computing Specs</h4>
          <ul>
            <li><strong>GPU:</strong> NVIDIA RTX 3090 (24GB VRAM)</li>
            <li><strong>CPU:</strong> Intel i9-12900K</li>
            <li><strong>Framework:</strong> Python 3.8, PyTorch 2.0</li>
            <li><strong>CUDA:</strong> Version 11.7</li>
          </ul>
        </div>
      </div>

      <div class="performance-stats">
        <h3 style="color: white; border-bottom: 2px solid white;">‚ö° Performance Metrics</h3>
        <div class="stats-grid">
          <div class="stat-item">
            <h4>12-18 FPS</h4>
            <p>Real-time Pipeline</p>
          </div>
          <div class="stat-item">
            <h4>85W</h4>
            <p>Power Consumption</p>
          </div>
          <div class="stat-item">
            <h4>¬±5ms</h4>
            <p>Sync Tolerance</p>
          </div>
          <div class="stat-item">
            <h4>72%</h4>
            <p>Feature Accuracy</p>
          </div>
        </div>
      </div>
    </div>

    <div class="technical-section">
      <h3>1. Data Acquisition and Preprocessing</h3>
      <p>Our system collects synchronized multi-modal sensor data with hardware-triggered alignment and advanced preprocessing for optimal performance under challenging environmental conditions.</p>
      
      <div class="feature-list">
        <h4>üîç Image Enhancement Pipeline</h4>
        <ul>
          <li><strong>CLAHE Processing:</strong> Contrast-limited adaptive histogram equalization in YUV color space</li>
          <li><strong>Depth Map Correction:</strong> Uniform depth maps with 1m baseline for continuity</li>
          <li><strong>Hardware Synchronization:</strong> ¬±5ms alignment tolerance across all sensors</li>
          <li><strong>TUM Format:</strong> 7-DOF poses with rigorous quaternion normalization</li>
        </ul>
      </div>

      <div class="code-block">
# Image Enhancement for Turbidity Correction
yuv_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2YUV)
yuv_img[:,:,0] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(yuv_img[:,:,0])
enhanced_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)

# Hardware-triggered IMU synchronization with timestamp validation
# Trajectory initialization using TUM format with quaternion normalization
      </div>
    </div>

    <div class="technical-section">
      <h3>2. Feature Extraction and Loop Closure</h3>
      <p>Advanced hierarchical feature extraction using ResNet50 backbone with optimized descriptor matching for real-time loop closure detection.</p>
      
      <div class="spec-grid">
        <div class="spec-card">
          <h4>üß† Neural Architecture</h4>
          <ul>
            <li><strong>Backbone:</strong> ResNet50 pre-trained on ImageNet</li>
            <li><strong>Output:</strong> 2048-dimensional global descriptors</li>
            <li><strong>Accuracy:</strong> 72% at 4 NTU turbidity</li>
            <li><strong>Outperforms:</strong> ORB, SIFT, SuperPoint (&lt;30%)</li>
          </ul>
        </div>
        <div class="spec-card">
          <h4>üìä Vocabulary System</h4>
          <ul>
            <li><strong>BoW Size:</strong> 500 visual words</li>
            <li><strong>Clustering:</strong> MiniBatchKMeans (batch_size=1000)</li>
            <li><strong>Similarity:</strong> Cosine similarity matching</li>
            <li><strong>Threshold:</strong> Œ∏=0.9 for loop closure</li>
          </ul>
        </div>
      </div>
    </div>

    <div class="technical-section">
      <h3>3. Multi-Model Object Detection</h3>
      <p>Robust object detection pipeline combining three complementary models for comprehensive coverage and accuracy in marine environments.</p>
      
      <div class="feature-list">
        <h4>üéØ Detection Models</h4>
        <ul>
          <li><strong>YOLOv8n:</strong> Real-time detection at 45 FPS on NVIDIA Jetson AGX</li>
          <li><strong>DETR:</strong> Attention-driven accuracy for small objects (ResNet50 backbone)</li>
          <li><strong>Faster R-CNN:</strong> Enhanced recall for partially occluded targets (ResNet50-FPN)</li>
        </ul>
      </div>

      <div class="code-block">
def filter_detections(boxes, scores, labels, img_shape, min_area=500, conf_thresh=0.5):
    valid = []
    for box, score, label in zip(boxes, scores, labels):
        area = (box[2]-box[0])*(box[3]-box[1])
        if (score >= conf_thresh and area >= min_area and 
            0 <= box[0] < img_shape[1] and 0 <= box[1] < img_shape[0]):
            valid.append((box, score, label))
    return valid

# Multi-stage filtering with confidence thresholds:
# YOLOv8: 0.3, Faster R-CNN/DETR: 0.5, Min area: 500px¬≤
      </div>
    </div>

    <div class="technical-section">
      <h3>4. Pose Refinement and Optimization</h3>
      <p>Two-stage pose refinement combining IMU pre-integration with graph-based optimization for robust camera pose estimation.</p>
      
      <div class="spec-grid">
        <div class="spec-card">
          <h4>üîÑ IMU Pre-integration</h4>
          <ul>
            <li><strong>Compensation:</strong> High-frequency motion artifacts</li>
            <li><strong>Damping Factor:</strong> Œ±=0.85</li>
            <li><strong>Translation Offset:</strong> Linear acceleration integration</li>
          </ul>
        </div>
        <div class="spec-card">
          <h4>üìà Graph Optimization</h4>
          <ul>
            <li><strong>Framework:</strong> g2o with SE(3) vertices</li>
            <li><strong>Iterations:</strong> 20 with early termination</li>
            <li><strong>Error Threshold:</strong> &lt;1.2 pixels reprojection</li>
          </ul>
        </div>
      </div>

      <div class="code-block">
# IMU-based pose refinement with damping
refined_pose[:3,3] += Œ± * imu_data[frame_idx,:3]  # Œ±=0.85 damping factor

# g2o optimization setup
optimizer = g2o.SparseOptimizer() 
solver = g2o.BlockSolverSE3(g2o.LinearSolverEigenSE3())
optimizer.set_algorithm(g2o.OptimizationAlgorithmLevenberg(solver))
      </div>
    </div>

    <div class="technical-section">
      <h3>5. 3D Reconstruction</h3>
      <p>Progressive point cloud construction with adaptive voxelization and selective fusion for optimal reconstruction quality.</p>
      
      <div class="feature-list">
        <h4>üèóÔ∏è Reconstruction Features</h4>
        <ul>
          <li><strong>Dynamic Voxelization:</strong> 2mm to 10mm based on turbidity</li>
          <li><strong>Bounded Volume:</strong> 10m √ó 10m √ó 5m working space</li>
          <li><strong>Selective Fusion:</strong> Minimum 500 valid feature correspondences</li>
          <li><strong>Async Processing:</strong> 5Hz reconstruction thread</li>
        </ul>
      </div>

      <div class="code-block">
# Progressive RGBD integration with Open3D
PCD = o3d.geometry.PointCloud.create_from_rgbd_image(
    o3d.geometry.RGBDImage(
        o3d.geometry.Image(RGB),
        o3d.geometry.Image(depth)),
    intrinsic,
    extrinsic=np.linalg.inv(pose)
)
PCD = PCD.voxel_down_sample(voxel_size=current_voxel_size)
      </div>
    </div>

    <div class="technical-section">
      <h3>6. Implementation Details</h3>
      <p>Optimized implementation with advanced memory management, GPU acceleration, and multi-threaded processing for real-time performance.</p>
      
      <div class="spec-grid">
        <div class="spec-card">
          <h4>üöÄ Optimization Features</h4>
          <ul>
            <li><strong>Memory Management:</strong> Non-blocking GPU transfers</li>
            <li><strong>Batch Processing:</strong> 32-image batches</li>
            <li><strong>Thread Safety:</strong> Lock guard for shared resources</li>
            <li><strong>GPU Acceleration:</strong> Deep feature extraction</li>
          </ul>
        </div>
        <div class="spec-card">
          <h4>üìö Technology Stack</h4>
          <ul>
            <li><strong>Languages:</strong> Python 3.8, CUDA 11.7</li>
            <li><strong>Frameworks:</strong> PyTorch 2.0, OpenCV, Open3D</li>
            <li><strong>Processing:</strong> Multi-threaded real-time</li>
            <li><strong>Hardware:</strong> RTX 3090, i9-12900K</li>
          </ul>
        </div>
      </div>
    </div>

    <div class="performance-stats">
      <h3 style="color: white; border-bottom: 2px solid white;">üéØ Key Achievements</h3>
      <div style="margin-top: 15px;">
        <p>‚úÖ <strong>Real-time Performance:</strong> 12-18 FPS pipeline execution across all experiments</p>
        <p>‚úÖ <strong>Energy Efficiency:</strong> 85W power consumption during active mapping operations</p>
        <p>‚úÖ <strong>Robust Feature Matching:</strong> 72% accuracy at 4 NTU turbidity conditions</p>
        <p>‚úÖ <strong>Synchronized Data Fusion:</strong> Multi-sensor integration with ¬±5ms precision</p>
        <p>‚úÖ <strong>Advanced Computer Vision:</strong> Multi-model detection with optimized filtering</p>
      </div>
    </div>

    <div style="text-align: center; margin: 30px 0;">
      <a href="agricultural_technology_portfolio.html" style="display: inline-block; background: linear-gradient(45deg, #007BFF, #0056b3); color: white; padding: 15px 30px; text-decoration: none; border-radius: 30px; font-weight: bold; font-size: 16px; box-shadow: 0 10px 30px rgba(0,123,255,0.3); transition: all 0.3s ease;"
         onmouseover="this.style.transform='translateY(-3px)'; this.style.boxShadow='0 15px 40px rgba(0,123,255,0.4)'" 
         onmouseout="this.style.transform='translateY(0px)'; this.style.boxShadow='0 10px 30px rgba(0,123,255,0.3)'">
        ü§ñ Explore Our Technology Portfolio
      </a>
    </div>
  </main>

  <footer>
    <p>&copy; 2025 Worldlight Agri Consult Labs. All rights reserved.</p>
  </footer>
</body>
</html>
